{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2:  Validação Cruzada Para Seleção de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos:\n",
    "\n",
    "O objetivo desse desafio é compreender como funciona a validação cruzada e os benefícios em se utilizar essa técnica para selecionar modelos mais genéricos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceitos:\n",
    "\n",
    "A validação cruzada é uma técnica de avaliação de um modelo em treinamento que permite estimar a capacidade de **generalização** do mesmo. A idéia por trás da técnica é validar qual seria o desempenho do modelo, treinado com uma parte dados, sobre o resto dos dados, nunca vistos antes pelo modelo. \n",
    "\n",
    "Essa técnica possibilita que se teste essa hipótese sem ser necessário ter uma base de testes extra, o que é muito útil quando se têm poucos dados. O diagrama abaixo resume a idéia central da técnica:\n",
    "\n",
    "\n",
    "![Diagrama explicativo: Cross-Validation usando K-Fold com ${K = 10}$](images/k-fold-diagram.png)\n",
    "\n",
    "A técnica mais comum, denominada `K-Fold`, consiste em particionar o dataset em $K$ grupos, treinar com $K-1$ grupos de dados e validar o modelo treinado sobre o grupo restante. Deve-se repetir esse passo $K$ vezes, para que todos os grupos sejam usados, e então calcular as métricas de avaliação como a média das métricas calculadas em cada iteração. Uma outra maneira de se fazer isso é armazenar a predição sobre todos os dados **quando em validação** e calcular as métricas de desempenho sobre essas predições.\n",
    "\n",
    "O limite dessa técnica é o `Leave-One-Out`, caso é o extremo em que se particiona o dataset em $N$ grupos. Esse limite, quando possível, traz a informação mais acurada sobre a capacidade de generalização do modelo. Essa técnica tem como desvantagem a quantidade enorme de treinamentos realizados: um para cada elemento da base de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics.regression import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid, KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre o Case\n",
    "\n",
    "### Case baseado no dataset do Kaggle: \"California Housing Prices\"\n",
    "\n",
    "Esse desafio é baseado em um dataset aberto do Kaggle ([https://www.kaggle.com](https://www.kaggle.com)) de 2018, de onde é possível estimar o preço de um imóvel pertencente a uma dada região na Califórnia. \n",
    "\n",
    "O dataset original foi extraído do repositório StatLib, que não está mais disponível. Os dados que o compôem foram retirados do Censo realizado na Califórnia em 1990 e modificado para servir como base de treinamento.\n",
    "\n",
    "\n",
    "Link para o dataset no Kaggle: [https://www.kaggle.com/harrywang/housing/data](https://www.kaggle.com/harrywang/housing/data)\n",
    "\n",
    "\n",
    "### Descrição dos Dados Originais:\n",
    "\n",
    "#### Tamanho do Dataset:\n",
    "\n",
    "* `20.640` data points\n",
    "\n",
    "#### Variável dependente:\n",
    "\n",
    "* `median_house_value`:  (float) variável dependente com o valor da mediana do preço de imóvel na região\n",
    "\n",
    "#### Features: \n",
    "\n",
    "* `longitude`/`latitude`: (floats) posição global da região\n",
    "* `housing_median_age`: (float) mediana da idade (em anos) das casas da região\n",
    "* `total_rooms`: (float) total de aposentos da região\n",
    "* `total_bedrooms`: (float) total de quartos da região\n",
    "* `population`: (float) população total da região\n",
    "* `households`: (float) quantidade total de imóveis da região\n",
    "* `median_income`: (float) mediana do salário (por hora) de uma pessoa na região\n",
    "* `ocean_proximity`: (string) categorias relativas à distância do oceano\n",
    "\n",
    "\n",
    "### Modificação dos dados para o Desafio:\n",
    "\n",
    "Para tornar o desafio mais fácil de avaliar, a massa de dados original foi dividida em duas massas, uma para treino e outra para teste, ambas contendo pouco mais de `10.000` elementos. \n",
    "\n",
    "Por motivos didáticos, alguns elementos da massa de treino foram removidos e, sobre os elementos restantes, foi aplicada uma Feature Engineering. Não é necesário se preocupar com o que é uma Feature Engineering agora, será o tema da Aula 20. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/feature_engineered_california_housing_train.csv\", sep=\"\\t\", index_col=0)\n",
    "x_train = dataset.drop([\"median_house_value\"], axis=1)\n",
    "y_train = dataset[[\"median_house_value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"shape: {x_train.shape}\")\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"shape: {y_train.shape}\")\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/feature_engineered_california_housing_test.csv\", sep=\"\\t\", index_col=0)\n",
    "x_test = dataset.drop([\"median_house_value\"], axis=1)\n",
    "y_test = dataset[[\"median_house_value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"shape: {x_test.shape}\")\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"shape: {y_test.shape}\")\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando Features com Z-Score\n",
    "\n",
    "Passo importante quando se treina modelos lineares, por eliminar importâncias artificialmente grandes para features contendo valores muito grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zscore = StandardScaler().fit(x_train.loc[:, columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train.loc[:, columns] = zscore.transform(x_train.loc[:, columns])\n",
    "x_test.loc[:, columns] = zscore.transform(x_test.loc[:, columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Seleção de Hiperparâmetros\n",
    "\n",
    "O uso mais comum da técnica é a seleção dos `hiperparâmetros` que definem o modelo; \n",
    "diferente dos parâmetros do modelo, que são ajustados a cada iteração do treinamento, os hiperparâmetros são condições fixadas sob as quais o treinamento ocorre. Um exemplo de hiperparâmetro é o $alpha$, definido para treinamentos das regressões `Ridge` e `Lasso`.\n",
    "\n",
    "Nessa seção, será feita a busca pelos melhores hiperparâmetros de treinamento usando a $ElasticNet$, que combina a regularização `L1` e `L2` em um modelo único. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha dos Hiperparâmetros\n",
    "\n",
    "Os hiperparâmetros a serem variados são:\n",
    "* `alpha`: mesmo parâmetro visto em Regularização, define a intensidade da regularização no modelo.\n",
    "* `l1_ratio `: define o tipo de regularização, como mostrado abaixo:\n",
    "    * $l1\\_ratio = 1$: o treinamento ocorre com `L1` apenas\n",
    "    * $l1\\_ratio = 0$: o treinamento ocorre com `L2` apenas\n",
    "    * $0 \\leq l1\\_ratio \\leq 1$: o treinamento ocorre com uma combinação de `L1` com `L2` na proporção dada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variação dos hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hiperparâmetros\n",
    "param_grid = {\n",
    "    \"alpha\": np.logspace(1, 4, 11),          # Por quê `logspace`?\n",
    "    \"l1_ratio\": np.linspace(0.01, 1.0, 11),\n",
    "    \"max_iter\": [100],\n",
    "    \"positive\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treinamento dos modelos\n",
    "\n",
    "Usar o [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) para treinar um conjunto de modelos com a combinação de todos os hiperparâmetros.\n",
    "\n",
    "Parâmetros a serem utilizados:\n",
    "\n",
    "* `estimator`: [`ElasticNet()`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)\n",
    "* `param_grid `: `param_grid`\n",
    "* `scoring`: 'r2'\n",
    "* `cv`: usar [`KFold(n_splits=10, shuffle=True, random_state=42)`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "* `random_state`: 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Escreva a solução aqui \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Avaliação dos modelos treinados\n",
    "\n",
    "Mostrar uma tabela contendo todos os treinamentos e suas avaliações e escolher um range de exploração onde o modelo consegue ter uma performance melhor.\n",
    "\n",
    "Dica: usar a função [`heatmap`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) do `seaborn` para visualizar os melhores parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Escreva a solução aqui \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Estudo da influência do parâmetro $K$ sobre a generalização\n",
    "\n",
    "Quanto mais `folds` forem usados na validação cruzada, mais realista será a estimativa do poder de generalização do modelo treinado. Como já foi citado, o uso de `LeaveOneOut` é o mais próximo de trazer essa estimativa, com o contraponto de ser o mais pesado computacionalmente.\n",
    "\n",
    "Nessa seção, será feita uma comparação entre o desempenho dos modelos nas massas de validação (calculado com dados de treino durante a validação cruzada) e de teste. \n",
    "\n",
    "###### Importante:\n",
    "\n",
    "Os hipeparâmetros a serem variados nos treinamentos devem ser obtidos na última etapa do item **A**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Hiperparâmetros\n",
    "\n",
    "Preencher `params_grid` com as faixas de hiperparâmetros de melhor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Complete os espaços com ? \"\"\"\n",
    "param_grid = {\n",
    "    \"alpha\": ?,\n",
    "    \"l1_ratio\": ?,\n",
    "    \"max_iter\": [1000],\n",
    "    \"positive\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Treinar os modelos para os valores de $K$\n",
    "\n",
    "Treinar os modelos para cada valor de $K$ em `k_list`. Armazenar, para cada $K$, os valores de $R^2$ médio calculados sobre a massa de **treino** e de **validação** (testes dentro do *Cross Validation*) e o $R^2$ calculado sobre a massa de **testes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_list = [3, 5, 10, 20, 35, 60, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Escreva a solução aqui \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Avaliação da generalização\n",
    "\n",
    "Mostrar em um plot a comparação entre os valores de $R^2$ calculados sobre as massa de treino, teste e validação para cada variação de $K$. \n",
    "\n",
    "* Eixo X: valores de $K$\n",
    "* Eixo Y: valores de $R^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Escreva a solução aqui \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
